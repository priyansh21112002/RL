{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIpLcqE12VFc",
        "outputId": "ecbe962c-ddf4-4d5e-cb3f-7dff58688bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned Policy: [1 3 1 2 1 1 1 1 3 1 1 1 3 3 3 1]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the environment parameters\n",
        "num_states = 16  # Number of states in the grid map (4x4 matrix)\n",
        "num_actions = 4  # Number of possible actions (up, down, left, right)\n",
        "gamma = 0.9  # Discount factor\n",
        "\n",
        "# Define the rewards and penalties\n",
        "rewards = np.zeros(num_states)\n",
        "rewards[15] = 10  # Reward for reaching the goal location (state 15)\n",
        "rewards[[5, 7, 11, 12]] = -10  # Penalty for reaching trap locations (states 5, 7, 11, 12)\n",
        "rewards[[2,3,4,6,8,9,10,13,14]] = 1  # Rewards for each step in non - trap locations\n",
        "\n",
        "# Define the transition function\n",
        "def transition_function(state, action):\n",
        "    if action == 0:  # Move up\n",
        "        if state >= 4:\n",
        "            return state - 4\n",
        "        else:\n",
        "            return state\n",
        "    elif action == 1:  # Move down\n",
        "        if state < 12:\n",
        "            return state + 4\n",
        "        else:\n",
        "            return state\n",
        "    elif action == 2:  # Move left\n",
        "        if state % 4 != 0:\n",
        "            return state - 1\n",
        "        else:\n",
        "            return state\n",
        "    elif action == 3:  # Move right\n",
        "        if (state + 1) % 4 != 0:\n",
        "            return state + 1\n",
        "        else:\n",
        "            return state\n",
        "\n",
        "# Initialize the Q-value function\n",
        "Q = np.zeros((num_states, num_actions))\n",
        "\n",
        "# Policy Evaluation\n",
        "def policy_evaluation(Q, rewards, gamma, num_iterations):\n",
        "    for _ in range(num_iterations):\n",
        "        for state in range(num_states):\n",
        "            for action in range(num_actions):\n",
        "                next_state = transition_function(state, action)  # Transition function to get the next state\n",
        "                reward = rewards[state]  # Reward for the current state\n",
        "                Q[state, action] = reward + gamma * np.max(Q[next_state])  # Update Q-value using Bellman equation\n",
        "    return Q\n",
        "\n",
        "# Policy Iteration\n",
        "def policy_iteration(Q, rewards, gamma, num_iterations):\n",
        "    policy = np.argmax(Q, axis=1)  # Initialize the policy with the greedy action from the current Q-values\n",
        "    for _ in range(num_iterations):\n",
        "        Q = policy_evaluation(Q, rewards, gamma, 1)  # Perform policy evaluation for one iteration\n",
        "        policy_stable = True  # Flag to check if the policy has changed\n",
        "        for state in range(num_states):\n",
        "            old_action = policy[state]\n",
        "            new_action = np.argmax(Q[state])  # Update the policy with the greedy action from the updated Q-values\n",
        "            if old_action != new_action:\n",
        "                policy_stable = False  # Policy has changed\n",
        "            policy[state] = new_action\n",
        "        if policy_stable:\n",
        "            break  # Exit the loop if the policy is stable\n",
        "        if policy[15] == 0:  # Stop when goal state (state 24) is reached\n",
        "            break\n",
        "    return policy\n",
        "\n",
        "# Perform policy evaluation\n",
        "Q = policy_evaluation(Q, rewards, gamma, num_iterations=1000)\n",
        "\n",
        "# Perform policy iteration\n",
        "policy = policy_iteration(Q, rewards, gamma, num_iterations=1000)\n",
        "\n",
        "# Print the learned policy\n",
        "print(\"Learned Policy:\", policy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define RL agent\n",
        "def rl_agent(policy):\n",
        "    state = 0  # Start from the initial state\n",
        "    steps = 0  # Number of steps taken\n",
        "    while state != 15:  # Continue until the goal state is reached\n",
        "        action = policy[state]  # Select action from the policy\n",
        "        next_state = transition_function(state, action)  # Get the next state\n",
        "        reward = rewards[state]  # Get the reward for the current state\n",
        "        print(\"Step:\", steps, \"State:\", state, \"Action:\", action, \"Next State:\", next_state, \"Reward:\", reward)\n",
        "        state = next_state  # Update the current state\n",
        "        steps += 1  # Increment the number of steps taken\n",
        "\n",
        "    print(\"Goal reached in\", steps, \"steps!\")\n",
        "\n",
        "# Run the RL agent\n",
        "rl_agent(policy)\n"
      ],
      "metadata": {
        "id": "HEL0QA8P2z4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b486970b-a816-4d4a-e5d1-fa8813eb7c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0 State: 0 Action: 1 Next State: 4 Reward: 0.0\n",
            "Step: 1 State: 4 Action: 1 Next State: 8 Reward: 1.0\n",
            "Step: 2 State: 8 Action: 3 Next State: 9 Reward: 1.0\n",
            "Step: 3 State: 9 Action: 1 Next State: 13 Reward: 1.0\n",
            "Step: 4 State: 13 Action: 3 Next State: 14 Reward: 1.0\n",
            "Step: 5 State: 14 Action: 3 Next State: 15 Reward: 1.0\n",
            "Goal reached in 6 steps!\n"
          ]
        }
      ]
    }
  ]
}